{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ca8c1e1",
   "metadata": {},
   "source": [
    "# Imports and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e2e19fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fb9369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /Users/giangluong/Desktop/Tín hiệu CP, Coin/venv/lib/python3.13/site-packages (1.7.4.5)\n",
      "Requirement already satisfied: bleach in /Users/giangluong/Desktop/Tín hiệu CP, Coin/venv/lib/python3.13/site-packages (from kaggle) (6.2.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /Users/giangluong/Desktop/Tín hiệu CP, Coin/venv/lib/python3.13/site-packages (from kaggle) (2025.4.26)\n",
      "Requirement already satisfied: charset-normalizer in /Users/giangluong/Desktop/Tín hiệu CP, Coin/venv/lib/python3.13/site-packages (from kaggle) (3.4.2)\n",
      "Requirement already satisfied: idna in /Users/giangluong/Desktop/Tín hiệu CP, Coin/venv/lib/python3.13/site-packages (from kaggle) (3.10)\n",
      "Requirement already satisfied: protobuf in /Users/giangluong/Desktop/Tín hiệu CP, Coin/venv/lib/python3.13/site-packages (from kaggle) (6.32.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/giangluong/Desktop/Tín hiệu CP, Coin/venv/lib/python3.13/site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: python-slugify in /Users/giangluong/Desktop/Tín hiệu CP, Coin/venv/lib/python3.13/site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: requests in /Users/giangluong/Desktop/Tín hiệu CP, Coin/venv/lib/python3.13/site-packages (from kaggle) (2.32.3)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /Users/giangluong/Desktop/Tín hiệu CP, Coin/venv/lib/python3.13/site-packages (from kaggle) (70.2.0)\n",
      "Requirement already satisfied: six>=1.10 in /Users/giangluong/Desktop/Tín hiệu CP, Coin/venv/lib/python3.13/site-packages (from kaggle) (1.17.0)\n",
      "Requirement already satisfied: text-unidecode in /Users/giangluong/Desktop/Tín hiệu CP, Coin/venv/lib/python3.13/site-packages (from kaggle) (1.3)\n",
      "Requirement already satisfied: tqdm in /Users/giangluong/Desktop/Tín hiệu CP, Coin/venv/lib/python3.13/site-packages (from kaggle) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in /Users/giangluong/Desktop/Tín hiệu CP, Coin/venv/lib/python3.13/site-packages (from kaggle) (2.4.0)\n",
      "Requirement already satisfied: webencodings in /Users/giangluong/Desktop/Tín hiệu CP, Coin/venv/lib/python3.13/site-packages (from kaggle) (0.5.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "884ee876",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ~/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "809ad1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv: /Users/giangluong/Documents/API_Kaggle/kaggle.json: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "mv ~/Documents/API_Kaggle/kaggle.json ~/.kaggle/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4716cdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir -p ./data/original_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111301cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kaggle competitions download -c histopathologic-cancer-detection -p ./data/original_data\n",
    "# import zipfile\n",
    "# import os\n",
    "\n",
    "# data_path = './data/original_data'\n",
    "# zip_files = [f for f in os.listdir(data_path) if f.endswith('.zip')]\n",
    "\n",
    "# for zip_file in zip_files:\n",
    "#     with zipfile.ZipFile(os.path.join(data_path, zip_file), 'r') as zip_ref:\n",
    "#         zip_ref.extractall(data_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7ce2ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGINAL_DATA_FOLDER = r\"./data/original_data\"\n",
    "PREPARED_DATA_FOLDER = r\"./data/prepared_data\"\n",
    "\n",
    "DO_SPLIT_VAL = False\n",
    "SAMPLE_PROPORTION = 0.1\n",
    "TEST_SPLIT = 0.2  # also used for val if DO_SPLIT_VAL is True\n",
    "\n",
    "# Transformation parameters as constants\n",
    "HORIZONTAL_FLIP_PROB = 0.5\n",
    "VERTICAL_FLIP_PROB = 0.0\n",
    "ROTATION_DEGREES = 15\n",
    "COLORJITTER_BRIGHTNESS = 0.15\n",
    "COLORJITTER_CONTRAST = 0.15\n",
    "COLORJITTER_SATURATION = 0.10\n",
    "COLORJITTER_HUE = 0.02\n",
    "GAUSSIANBLUR_KERNEL_SIZE = 3\n",
    "GAUSSIANBLUR_SIGMA = (0.1, 1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f29ed5f",
   "metadata": {},
   "source": [
    "# Load and sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc7e0bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f38a6374c348f90b587e046aac6079959adf3835</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c18f2d887b7ae4f6742ee445113fa1aef383ed77</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>755db6279dae599ebb4d39a9123cce439965282d</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bc3f0c64fb968ff4a8bd33af6971ecae77c75e08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>068aba587a4950175d04c680d38943fd488d6a9d</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220020</th>\n",
       "      <td>53e9aa9d46e720bf3c6a7528d1fca3ba6e2e49f6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220021</th>\n",
       "      <td>d4b854fe38b07fe2831ad73892b3cec877689576</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220022</th>\n",
       "      <td>3d046cead1a2a5cbe00b2b4847cfb7ba7cf5fe75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220023</th>\n",
       "      <td>f129691c13433f66e1e0671ff1fe80944816f5a2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220024</th>\n",
       "      <td>a81f84895ddcd522302ddf34be02eb1b3e5af1cb</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220025 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              id  label\n",
       "0       f38a6374c348f90b587e046aac6079959adf3835      0\n",
       "1       c18f2d887b7ae4f6742ee445113fa1aef383ed77      1\n",
       "2       755db6279dae599ebb4d39a9123cce439965282d      0\n",
       "3       bc3f0c64fb968ff4a8bd33af6971ecae77c75e08      0\n",
       "4       068aba587a4950175d04c680d38943fd488d6a9d      0\n",
       "...                                          ...    ...\n",
       "220020  53e9aa9d46e720bf3c6a7528d1fca3ba6e2e49f6      0\n",
       "220021  d4b854fe38b07fe2831ad73892b3cec877689576      1\n",
       "220022  3d046cead1a2a5cbe00b2b4847cfb7ba7cf5fe75      0\n",
       "220023  f129691c13433f66e1e0671ff1fe80944816f5a2      0\n",
       "220024  a81f84895ddcd522302ddf34be02eb1b3e5af1cb      1\n",
       "\n",
       "[220025 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df = pd.read_csv(os.path.join(ORIGINAL_DATA_FOLDER, \"train_labels.csv\"))\n",
    "labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c00e6c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220025, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c24099ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22002"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_size = int(len(labels_df) * SAMPLE_PROPORTION)\n",
    "sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9783b965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    130908\n",
       "1     89117\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df[\"label\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bf80041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8a0657ec177b9eb56818104dd2b47506c6a39527</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>afab792594de5e1d307921ce71056ae20c87fa63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4abdc97be8cfb42c396f85b7efb06f7d444d8166</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>033fdf44b55943ee73b8b40e94b789033463b136</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0cbd532db8b2bd65e8dab08250d157babc832f4d</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21997</th>\n",
       "      <td>681768428a6cad7eafcb31581464bab65784321a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21998</th>\n",
       "      <td>ecf900769a47084b571213ad9d01e5bd330c9e4e</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21999</th>\n",
       "      <td>3adca6cf48552e5b31e9ea3f942c91ef874ab030</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22000</th>\n",
       "      <td>cd5b2fa479d71e14265b554ff7aec534a0b21f0c</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22001</th>\n",
       "      <td>ef8aad0126cee42ed4a8f9a9e940801c36d5b040</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22002 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             id  label\n",
       "0      8a0657ec177b9eb56818104dd2b47506c6a39527      1\n",
       "1      afab792594de5e1d307921ce71056ae20c87fa63      0\n",
       "2      4abdc97be8cfb42c396f85b7efb06f7d444d8166      0\n",
       "3      033fdf44b55943ee73b8b40e94b789033463b136      1\n",
       "4      0cbd532db8b2bd65e8dab08250d157babc832f4d      0\n",
       "...                                         ...    ...\n",
       "21997  681768428a6cad7eafcb31581464bab65784321a      1\n",
       "21998  ecf900769a47084b571213ad9d01e5bd330c9e4e      1\n",
       "21999  3adca6cf48552e5b31e9ea3f942c91ef874ab030      0\n",
       "22000  cd5b2fa479d71e14265b554ff7aec534a0b21f0c      0\n",
       "22001  ef8aad0126cee42ed4a8f9a9e940801c36d5b040      0\n",
       "\n",
       "[22002 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform stratified sampling to keep the same ratio of 0 and 1 as the original data\n",
    "label_counts = labels_df[\"label\"].value_counts(normalize=True)\n",
    "n_0 = int(round(sample_size * label_counts[0]))\n",
    "n_1 = sample_size - n_0  # ensure total is exactly SAMPLE_SIZE\n",
    "\n",
    "stratified_sample_0 = labels_df[labels_df[\"label\"] == 0].sample(n=n_0, random_state=0)\n",
    "stratified_sample_1 = labels_df[labels_df[\"label\"] == 1].sample(n=n_1, random_state=0)\n",
    "\n",
    "stratified_sample = pd.concat(\n",
    "    [stratified_sample_0, stratified_sample_1], ignore_index=True\n",
    ")\n",
    "stratified_sample = stratified_sample.sample(frac=1, random_state=0).reset_index(\n",
    "    drop=True\n",
    ")  # shuffle\n",
    "\n",
    "stratified_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6d020fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    13091\n",
       "1     8911\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stratified_sample[\"label\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d2c9a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22002\n"
     ]
    }
   ],
   "source": [
    "original_data_dir = os.path.join(ORIGINAL_DATA_FOLDER, \"train\")  # directory of files\n",
    "prepared_data_dir = os.path.join(PREPARED_DATA_FOLDER, \"full_data\")\n",
    "\n",
    "# Create the destination directory if it doesn't exist\n",
    "os.makedirs(prepared_data_dir, exist_ok=True)\n",
    "\n",
    "file_names = [f\"{img_id}.tif\" for img_id in stratified_sample[\"id\"]]\n",
    "print(len(file_names))\n",
    "full_filenames = [\n",
    "    os.path.join(original_data_dir, f) for f in file_names\n",
    "]  # get the full path to images\n",
    "\n",
    "# Copy files to the prepared_data_dir\n",
    "for src_path in full_filenames:\n",
    "    dst_path = os.path.join(prepared_data_dir, os.path.basename(src_path))\n",
    "    shutil.copy2(src_path, dst_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "795c0df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stratified_sample.to_csv(\n",
    "    os.path.join(PREPARED_DATA_FOLDER, \"full_data_labels.csv\"), index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c639eeb",
   "metadata": {},
   "source": [
    "# Train, val, test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "947435e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)  # fix random seed\n",
    "\n",
    "\n",
    "class pytorch_data(Dataset):\n",
    "    def __init__(self, data_dir, transform, data_type=\"train\"):\n",
    "        # Get Image File Names\n",
    "        cdm_data = os.path.join(data_dir, data_type)  # directory of files\n",
    "\n",
    "        file_names = [f for f in os.listdir(cdm_data) if f != \".gitkeep\"]\n",
    "\n",
    "        self.full_filenames = [\n",
    "            os.path.join(cdm_data, f) for f in file_names\n",
    "        ]  # get the full path to images\n",
    "\n",
    "        # Get Labels\n",
    "        labels_data = os.path.join(data_dir, f\"{data_type}_labels.csv\")\n",
    "        labels_df = pd.read_csv(labels_data)\n",
    "        labels_df.set_index(\"id\", inplace=True)  # set data frame index to id\n",
    "\n",
    "        self.labels = []\n",
    "        for filename in file_names:\n",
    "            try:\n",
    "                label = labels_df.loc[filename[:-4]].values[0]\n",
    "                self.labels.append(label)\n",
    "            except Exception as e:\n",
    "                print(f\"Problem with filename: {filename} - {e}\")\n",
    "                raise\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.full_filenames)  # size of dataset\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # open image, apply transforms and return with label\n",
    "        image = Image.open(self.full_filenames[idx])  # Open Image with PIL\n",
    "        image = self.transform(image)  # Apply Specific Transformation to Image\n",
    "        return image, self.labels[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "400d3359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define transformation that converts a PIL image into PyTorch tensors\n",
    "from torchvision import transforms\n",
    "\n",
    "data_transformer = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4cb7665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an object of the custom dataset for the train folder.\n",
    "img_dataset = pytorch_data(\n",
    "    PREPARED_DATA_FOLDER, data_transformer, \"full_data\"\n",
    ")  # Histopathalogic images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d716928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset size: 17601\n",
      "test dataset size: 4401\n"
     ]
    }
   ],
   "source": [
    "# Get all labels from the dataset\n",
    "all_labels = np.array(img_dataset.labels)\n",
    "all_indices = np.arange(len(img_dataset))\n",
    "\n",
    "# First, split into train and test in a stratified way\n",
    "train_indices, test_indices = train_test_split(\n",
    "    all_indices, test_size=TEST_SPLIT, stratify=all_labels, random_state=42\n",
    ")\n",
    "\n",
    "if DO_SPLIT_VAL:\n",
    "    # Further split train into train/val in a stratified way\n",
    "    train_labels = all_labels[train_indices]\n",
    "    train_indices, val_indices = train_test_split(\n",
    "        train_indices,\n",
    "        test_size=TEST_SPLIT / (1 - TEST_SPLIT),\n",
    "        stratify=train_labels,\n",
    "        random_state=42,\n",
    "    )\n",
    "    val_ts = torch.utils.data.Subset(img_dataset, val_indices)\n",
    "\n",
    "train_ts = torch.utils.data.Subset(img_dataset, train_indices)\n",
    "test_ts = torch.utils.data.Subset(img_dataset, test_indices)\n",
    "\n",
    "# Save the labels to respective CSV files in PREPARED_DATA_FOLDER\n",
    "# Get the corresponding filenames for each split\n",
    "all_filenames = np.array(img_dataset.full_filenames)\n",
    "\n",
    "\n",
    "def get_id_from_path(path):\n",
    "    # Assumes filename is the last part and ends with .tif\n",
    "    return os.path.splitext(os.path.basename(path))[0]\n",
    "\n",
    "\n",
    "# Ensure the PREPARED_DATA_FOLDER exists\n",
    "os.makedirs(PREPARED_DATA_FOLDER, exist_ok=True)\n",
    "\n",
    "# Train labels\n",
    "train_ids = [get_id_from_path(all_filenames[i]) for i in train_indices]\n",
    "train_labels_arr = all_labels[train_indices]\n",
    "train_df = pd.DataFrame({\"id\": train_ids, \"label\": train_labels_arr})\n",
    "train_df.to_csv(os.path.join(PREPARED_DATA_FOLDER, \"train_labels.csv\"), index=False)\n",
    "\n",
    "# Validation labels (if applicable)\n",
    "if DO_SPLIT_VAL:\n",
    "    val_ids = [get_id_from_path(all_filenames[i]) for i in val_indices]\n",
    "    val_labels_arr = all_labels[val_indices]\n",
    "    val_df = pd.DataFrame({\"id\": val_ids, \"label\": val_labels_arr})\n",
    "    val_df.to_csv(os.path.join(PREPARED_DATA_FOLDER, \"val_labels.csv\"), index=False)\n",
    "\n",
    "# Test labels\n",
    "test_ids = [get_id_from_path(all_filenames[i]) for i in test_indices]\n",
    "test_labels_arr = all_labels[test_indices]\n",
    "test_df = pd.DataFrame({\"id\": test_ids, \"label\": test_labels_arr})\n",
    "test_df.to_csv(os.path.join(PREPARED_DATA_FOLDER, \"test_labels.csv\"), index=False)\n",
    "\n",
    "print(\"train dataset size:\", len(train_ts))\n",
    "if DO_SPLIT_VAL:\n",
    "    print(\"validation dataset size:\", len(val_ts))\n",
    "print(\"test dataset size:\", len(test_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4481e362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 96, 96]) 1\n",
      "torch.Size([3, 96, 96]) 1\n",
      "torch.Size([3, 96, 96]) 1\n",
      "torch.Size([3, 96, 96]) 0\n",
      "torch.Size([3, 96, 96]) 0\n",
      "torch.Size([3, 96, 96]) 0\n",
      "torch.Size([3, 96, 96]) 1\n"
     ]
    }
   ],
   "source": [
    "# getting the torch tensor image & target variable\n",
    "ii = -1\n",
    "for x, y in train_ts:\n",
    "    print(x.shape, y)\n",
    "    ii += 1\n",
    "    if ii > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b763d65d",
   "metadata": {},
   "source": [
    "# Transform and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c0e78a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformations for the training dataset, with explanations for each step\n",
    "tr_transf = transforms.Compose(\n",
    "    [\n",
    "        # Randomly flip the image horizontally with a probability to augment data and help the model generalize\n",
    "        transforms.RandomHorizontalFlip(p=HORIZONTAL_FLIP_PROB),\n",
    "        # Randomly flip the image vertically with a probability (disabled here).\n",
    "        # Set to 0.5 only if the label is invariant to vertical flips.\n",
    "        transforms.RandomVerticalFlip(p=VERTICAL_FLIP_PROB),\n",
    "        # Randomly rotate the image within a range of ±ROTATION_DEGREES degrees to introduce rotational invariance.\n",
    "        # The output image keeps its original size (no expand).\n",
    "        transforms.RandomRotation(degrees=ROTATION_DEGREES),\n",
    "        # Randomly change the brightness, contrast, saturation, and hue of the image to simulate different lighting conditions.\n",
    "        transforms.ColorJitter(\n",
    "            brightness=COLORJITTER_BRIGHTNESS,  # Adjust brightness by ±15%\n",
    "            contrast=COLORJITTER_CONTRAST,  # Adjust contrast by ±15%\n",
    "            saturation=COLORJITTER_SATURATION,  # Adjust saturation by ±10%\n",
    "            hue=COLORJITTER_HUE,  # Adjust hue by ±2%\n",
    "        ),\n",
    "        # Apply Gaussian blur with a kernel size and a sigma randomly chosen in the range.\n",
    "        # This helps the model become robust to slight blurring in images.\n",
    "        transforms.GaussianBlur(\n",
    "            kernel_size=GAUSSIANBLUR_KERNEL_SIZE, sigma=GAUSSIANBLUR_SIGMA\n",
    "        ),\n",
    "        # Convert the PIL Image or numpy.ndarray to a PyTorch tensor.\n",
    "        # Note: Do not normalize here; normalization can be done later if needed.\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d32b8ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset_split(\n",
    "    dataset,\n",
    "    subset_indices,\n",
    "    out_dir,\n",
    "    img_dataset,\n",
    "    transform=None,\n",
    "    apply_transform=False,\n",
    "    file_format=\"TIFF\",\n",
    "):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    for local_idx, ds_idx in enumerate(subset_indices):\n",
    "        orig_path = img_dataset.full_filenames[ds_idx]\n",
    "        base_name = os.path.splitext(os.path.basename(orig_path))[0]\n",
    "        save_path = os.path.join(out_dir, f\"{base_name}.tif\")\n",
    "\n",
    "        img, label = dataset[local_idx]\n",
    "\n",
    "        if isinstance(img, Image.Image):\n",
    "            img_pil = img\n",
    "        else:\n",
    "            img_pil = transforms.ToPILImage()(img)\n",
    "\n",
    "        if apply_transform and transform is not None:\n",
    "            img_transformed = transform(img_pil)\n",
    "            if not isinstance(img_transformed, Image.Image):\n",
    "                img_transformed = transforms.ToPILImage()(img_transformed)\n",
    "            img_to_save = img_transformed\n",
    "        else:\n",
    "            if not isinstance(img_pil, Image.Image):\n",
    "                img_pil = transforms.ToPILImage()(img_pil)\n",
    "            img_to_save = img_pil\n",
    "\n",
    "        img_to_save.save(save_path, format=file_format)\n",
    "\n",
    "\n",
    "# --- Save train set with transformation ---\n",
    "out_dir = os.path.join(PREPARED_DATA_FOLDER, \"train\")\n",
    "subset_indices = (\n",
    "    train_ts.indices if hasattr(train_ts, \"indices\") else list(range(len(train_ts)))\n",
    ")\n",
    "save_dataset_split(\n",
    "    train_ts,\n",
    "    subset_indices,\n",
    "    out_dir,\n",
    "    img_dataset,\n",
    "    transform=tr_transf if \"tr_transf\" in globals() else None,\n",
    "    apply_transform=True,\n",
    "    file_format=\"TIFF\",\n",
    ")\n",
    "\n",
    "# --- Save val set without transformation ---\n",
    "if DO_SPLIT_VAL:\n",
    "    out_dir_val = os.path.join(PREPARED_DATA_FOLDER, \"val\")\n",
    "    val_subset_indices = (\n",
    "        val_ts.indices if hasattr(val_ts, \"indices\") else list(range(len(val_ts)))\n",
    "    )\n",
    "    save_dataset_split(\n",
    "        val_ts,\n",
    "        val_subset_indices,\n",
    "        out_dir_val,\n",
    "        img_dataset,\n",
    "        transform=None,\n",
    "        apply_transform=False,\n",
    "        file_format=\"TIFF\",\n",
    "    )\n",
    "\n",
    "# --- Save test set without transformation ---\n",
    "out_dir_test = os.path.join(PREPARED_DATA_FOLDER, \"test\")\n",
    "test_subset_indices = (\n",
    "    test_ts.indices if hasattr(test_ts, \"indices\") else list(range(len(test_ts)))\n",
    ")\n",
    "save_dataset_split(\n",
    "    test_ts,\n",
    "    test_subset_indices,\n",
    "    out_dir_test,\n",
    "    img_dataset,\n",
    "    transform=None,\n",
    "    apply_transform=False,\n",
    "    file_format=\"TIFF\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9692b671",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vn30_env",
   "language": "python",
   "name": "vn30_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
